# Internal Linking Opportunity Analyzer - Sample Usage

This notebook demonstrates how to use the Internal Linking Analyzer tool to identify internal linking opportunities based on your website content and Google Search Console data.
## Step 1: Setup and Installation

First, let's install all required packages:
!pip install requests beautifulsoup4 pandas spacy
!python -m spacy download en_core_web_sm
## Step 2: Import the Script

You can either upload the `internal_linking_analyzer.py` file or copy-paste the code directly:
# Option 1: Upload the file
try:
    from google.colab import files
    uploaded = files.upload()  # Upload internal_linking_analyzer.py
    %run internal_linking_analyzer.py
except ImportError:
    print("Not running in Google Colab. Skip this step if running locally.")
## Step 3: Run the Analysis

Execute the main function to run the analysis:
# Run the analysis
run_internal_linking_analysis()
## Alternative: Manual Step-by-Step Execution

If you prefer more control over the process, you can run each step manually:
# Import required modules
from internal_linking_analyzer import InternalLinkingAnalyzer
from google.colab import files
import pandas as pd
from io import StringIO

# Initialize the analyzer
analyzer = InternalLinkingAnalyzer()

# Upload sitemap file
print("Upload your XML sitemap file:")
uploaded = files.upload()
sitemap_file = list(uploaded.keys())[0]
sitemap_content = uploaded[sitemap_file].decode('utf-8')

# Extract URLs from sitemap
analyzer.sitemap_urls = analyzer.extract_urls_from_sitemap(sitemap_content)
print(f"Extracted {len(analyzer.sitemap_urls)} URLs from sitemap")

# Upload GSC data
print("\nUpload your Google Search Console CSV export:")
uploaded = files.upload()
gsc_file = list(uploaded.keys())[0]
gsc_content = uploaded[gsc_file].decode('utf-8')

# Parse GSC data
analyzer.gsc_data = analyzer.parse_gsc_data(gsc_content)

# Display a sample of GSC data
if analyzer.gsc_data is not None:
    display(analyzer.gsc_data.head())
    
# Scrape URLs (limit to 10 for testing)
max_urls = 10  # Limit for testing
analyzer.scrape_urls(max_urls=max_urls)

# Find internal linking opportunities
analyzer.find_internal_linking_opportunities()

# Display a sample of opportunities
if analyzer.internal_linking_opportunities:
    df = pd.DataFrame(analyzer.internal_linking_opportunities)
    display(df.head())
    
    # Export results
    output_filename = "internal_linking_opportunities.csv"
    analyzer.export_opportunities(output_filename)
## Sample Input Files

### Example XML Sitemap Format

```xml
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://www.example.com/</loc>
    <lastmod>2023-01-01</lastmod>
    <changefreq>daily</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://www.example.com/page1</loc>
    <lastmod>2023-01-01</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <!-- more URLs -->
</urlset>
```

### Example GSC CSV Format

```
Landing Page,Query,Clicks,Impressions,CTR,Position
https://www.example.com/page1,seo optimization,45,1200,3.75%,4.2
https://www.example.com/page2,internal linking,32,980,3.27%,5.1
https://www.example.com/page1,website optimization,22,850,2.59%,6.3
<!-- more rows -->
```
## Expected Output Format

The tool generates a CSV file with the following columns:

1. `source_url`: The page where an internal link will be added
2. `keyword`: The query or keyword to be used as anchor text for the link
3. `text_snippet`: A snippet of text where the hyperlink should be inserted
4. `target_url`: The destination URL for the internal link

Example output:

```
source_url,keyword,text_snippet,target_url
https://www.example.com/page1,internal linking,Learn more about internal linking to improve your SEO,https://www.example.com/page2
https://www.example.com/page2,SEO optimization,Implement proper SEO optimization techniques for better results,https://www.example.com/page1
```
